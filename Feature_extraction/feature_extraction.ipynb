{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sklearn.feature_extraction module can be used to extract features in a format supported by machine learning algorithms from datasets consisting of formats such as text and image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer, FeatureHasher\n",
    "\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature extraction methods\n",
    "\n",
    "- [1. Basic feature extraction](#1.)\n",
    "\n",
    "  - [1.1 DictVectorizer](#1.1)\n",
    "  - [1.2 FeatureHasher](#1.2)\n",
    "\n",
    "- [2. text feature extraction](#2.)\n",
    "\n",
    "- [3. images feature extraction](#3.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1. Basic feature extraction](#1.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.1 DictVectorizer](#1.1)\n",
    "\n",
    "The class DictVectorizer can be used to convert feature arrays represented as lists of standard Python dict objects to the NumPy/SciPy representation used by scikit-learn estimators.\n",
    "\n",
    "DictVectorizer implements what is called one-of-K or “one-hot” coding for categorical (aka nominal, discrete) features.\n",
    "\n",
    "In general DictVectorizer, like oneHotEnconding, but it has an advantage, inb which it can understan the numbercal data, so that it won't make it a binary features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.,  0.,  0., 33.],\n",
       "        [ 0.,  1.,  0., 12.],\n",
       "        [ 0.,  0.,  1., 18.]]),\n",
       " array(['city=Dubai', 'city=London', 'city=San Francisco', 'temperature'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurements = [\n",
    "    {\"city\": \"Dubai\", \"temperature\": 33.0},\n",
    "    {\"city\": \"London\", \"temperature\": 12.0},\n",
    "    {\"city\": \"San Francisco\", \"temperature\": 18.0},\n",
    "]\n",
    "\n",
    "vec = DictVectorizer()\n",
    "\n",
    "features = vec.fit_transform(measurements).toarray()\n",
    "columns = vec.get_feature_names_out()\n",
    "features, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city=Dubai</th>\n",
       "      <th>city=London</th>\n",
       "      <th>city=San Francisco</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city=Dubai  city=London  city=San Francisco  temperature\n",
       "0         1.0          0.0                 0.0         33.0\n",
       "1         0.0          1.0                 0.0         12.0\n",
       "2         0.0          0.0                 1.0         18.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(features, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2 FeatureHasher](#1.2)\n",
    "\n",
    "Implements feature hashing, aka the hashing trick.\n",
    "\n",
    "This class turns sequences of symbolic feature names (strings) into scipy.sparse matrices, using a hash function to compute the matrix column corresponding to a name. The hash function employed is the signed 32-bit version of Murmurhash3.\n",
    "\n",
    "This class is a low-memory alternative to DictVectorizer and CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0., -4., -1.,  0.,  0.,  0.,  0.,  0.,  2.],\n",
       "       [ 0.,  0.,  0., -2., -5.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "h = FeatureHasher(n_features=10, input_type=\"dict\")\n",
    "D = [{\"dog\": 1, \"cat\": 2, \"elephant\": 4}, {\"dog\": 2, \"run\": 5}]\n",
    "f = h.transform(D)\n",
    "f.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = FeatureHasher(n_features=15, input_type=\"string\", alternate_sign=False)\n",
    "raw_X = [[\"dog\", \"cat\", \"snake\"], [\"snake\", \"dog\"], [\"cat\", \"bird\"]]\n",
    "f = h.transform(raw_X)\n",
    "f.toarray()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
